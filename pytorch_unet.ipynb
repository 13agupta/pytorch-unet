{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 192, 192, 3)\n",
      "0 255\n",
      "(3, 6, 192, 192)\n",
      "0.0 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation\n",
    "\n",
    "# Generate some random images\n",
    "input_images, target_masks = simulation.generate_random_data(192, 192, count=3)\n",
    "\n",
    "for x in [input_images, target_masks]:\n",
    "    print(x.shape)\n",
    "    print(x.min(), x.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "# Left: Input image, Right: Target mask (Ground-truth)\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 1000, 'val': 200}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count, transform=None):\n",
    "        self.input_images, self.target_masks = simulation.generate_random_data(192, 192, count=count)        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return [image, mask]\n",
    "\n",
    "# use same transform for train/val for this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_set = SimDataset(1000, transform = trans)\n",
    "val_set = SimDataset(200, transform = trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3, 192, 192]) torch.Size([25, 6, 192, 192])\n",
      "0.0 1.0 0.024937065 0.15593328\n",
      "0.0 1.0 0.0050752317 0.071059614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2c8933de10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "    \n",
    "    return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "for x in [inputs.numpy(), masks.numpy()]:\n",
    "    print(x.min(), x.max(), x.mean(), x.std())\n",
    "\n",
    "plt.imshow(reverse_transform(inputs[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-15          [-1, 256, 28, 28]               0\n",
      "           Conv2d-16          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-17          [-1, 512, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "         Upsample-20          [-1, 512, 56, 56]               0\n",
      "           Conv2d-21          [-1, 256, 56, 56]       1,769,728\n",
      "             ReLU-22          [-1, 256, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-24          [-1, 256, 56, 56]               0\n",
      "         Upsample-25        [-1, 256, 112, 112]               0\n",
      "           Conv2d-26        [-1, 128, 112, 112]         442,496\n",
      "             ReLU-27        [-1, 128, 112, 112]               0\n",
      "           Conv2d-28        [-1, 128, 112, 112]         147,584\n",
      "             ReLU-29        [-1, 128, 112, 112]               0\n",
      "         Upsample-30        [-1, 128, 224, 224]               0\n",
      "           Conv2d-31         [-1, 64, 224, 224]         110,656\n",
      "             ReLU-32         [-1, 64, 224, 224]               0\n",
      "           Conv2d-33         [-1, 64, 224, 224]          36,928\n",
      "             ReLU-34         [-1, 64, 224, 224]               0\n",
      "           Conv2d-35          [-1, 6, 224, 224]             390\n",
      "================================================================\n",
      "Total params: 7,783,238\n",
      "Trainable params: 7,783,238\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_unet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = pytorch_unet.UNet(6)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        \n",
    "    pred = F.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "    \n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 0/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.596013, dice: 0.991593, loss: 0.793803\n",
      "val: bce: 0.096567, dice: 0.997324, loss: 0.546945\n",
      "saving best model\n",
      "Epoch 1/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.074634, dice: 0.997200, loss: 0.535917\n",
      "val: bce: 0.043836, dice: 0.997034, loss: 0.520435\n",
      "saving best model\n",
      "Epoch 2/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.037085, dice: 0.994101, loss: 0.515593\n",
      "val: bce: 0.028580, dice: 0.984056, loss: 0.506318\n",
      "saving best model\n",
      "Epoch 3/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.024725, dice: 0.891580, loss: 0.458153\n",
      "val: bce: 0.020269, dice: 0.824877, loss: 0.422573\n",
      "saving best model\n",
      "Epoch 4/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.021046, dice: 0.769863, loss: 0.395454\n",
      "val: bce: 0.026358, dice: 0.705562, loss: 0.365960\n",
      "saving best model\n",
      "Epoch 5/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.027872, dice: 0.663105, loss: 0.345488\n",
      "val: bce: 0.029249, dice: 0.611689, loss: 0.320469\n",
      "saving best model\n",
      "Epoch 6/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.026741, dice: 0.560595, loss: 0.293668\n",
      "val: bce: 0.021215, dice: 0.511328, loss: 0.266271\n",
      "saving best model\n",
      "Epoch 7/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.019200, dice: 0.486246, loss: 0.252723\n",
      "val: bce: 0.016829, dice: 0.470223, loss: 0.243526\n",
      "saving best model\n",
      "Epoch 8/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.016377, dice: 0.444461, loss: 0.230419\n",
      "val: bce: 0.014764, dice: 0.410405, loss: 0.212584\n",
      "saving best model\n",
      "Epoch 9/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.015797, dice: 0.407906, loss: 0.211852\n",
      "val: bce: 0.014335, dice: 0.380767, loss: 0.197551\n",
      "saving best model\n",
      "Epoch 10/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.014603, dice: 0.362565, loss: 0.188584\n",
      "val: bce: 0.014022, dice: 0.361106, loss: 0.187564\n",
      "saving best model\n",
      "Epoch 11/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.013829, dice: 0.334916, loss: 0.174373\n",
      "val: bce: 0.012318, dice: 0.282740, loss: 0.147529\n",
      "saving best model\n",
      "Epoch 12/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.012466, dice: 0.280623, loss: 0.146544\n",
      "val: bce: 0.010865, dice: 0.274780, loss: 0.142823\n",
      "saving best model\n",
      "Epoch 13/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.012116, dice: 0.257375, loss: 0.134745\n",
      "val: bce: 0.011237, dice: 0.236742, loss: 0.123989\n",
      "saving best model\n",
      "Epoch 14/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.011636, dice: 0.235148, loss: 0.123392\n",
      "val: bce: 0.010612, dice: 0.219494, loss: 0.115053\n",
      "saving best model\n",
      "Epoch 15/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.011401, dice: 0.222405, loss: 0.116903\n",
      "val: bce: 0.011276, dice: 0.214543, loss: 0.112909\n",
      "saving best model\n",
      "Epoch 16/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.011501, dice: 0.224215, loss: 0.117858\n",
      "val: bce: 0.010296, dice: 0.212687, loss: 0.111492\n",
      "saving best model\n",
      "Epoch 17/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.011114, dice: 0.211406, loss: 0.111260\n",
      "val: bce: 0.010472, dice: 0.201274, loss: 0.105873\n",
      "saving best model\n",
      "Epoch 18/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.010793, dice: 0.204758, loss: 0.107775\n",
      "val: bce: 0.009672, dice: 0.199653, loss: 0.104662\n",
      "saving best model\n",
      "Epoch 19/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.010570, dice: 0.201119, loss: 0.105845\n",
      "val: bce: 0.010084, dice: 0.193097, loss: 0.101591\n",
      "saving best model\n",
      "Epoch 20/39\n",
      "----------\n",
      "LR 5e-05\n",
      "train: bce: 0.010354, dice: 0.199484, loss: 0.104919\n",
      "val: bce: 0.009286, dice: 0.190967, loss: 0.100127\n",
      "saving best model\n",
      "Epoch 21/39\n",
      "----------\n",
      "LR 5e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7f7088e7c41f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-63391c7519ec>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 6\n",
    "\n",
    "model = pytorch_unet.UNet(num_class).to(device)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)\n",
    "\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "import math\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "        \n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = model(inputs)\n",
    "\n",
    "pred = pred.data.cpu().numpy()\n",
    "print(pred.shape)\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
