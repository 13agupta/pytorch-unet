{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 192, 192, 3)\n",
      "0 255\n",
      "(3, 6, 192, 192)\n",
      "0.0 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation\n",
    "\n",
    "# Generate some random images\n",
    "input_images, target_masks = simulation.generate_random_data(192, 192, count=3)\n",
    "\n",
    "for x in [input_images, target_masks]:\n",
    "    print(x.shape)\n",
    "    print(x.min(), x.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "# Left: Input image, Right: Target mask\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 2000, 'val': 200}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count, transform=None):\n",
    "        self.input_images, self.target_masks = simulation.generate_random_data(192, 192, count=count)        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return [image, mask]\n",
    "\n",
    "# use same transform for train/val for this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "train_set = SimDataset(2000, transform = trans)\n",
    "val_set = SimDataset(200, transform = trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3, 192, 192]) torch.Size([25, 6, 192, 192])\n",
      "-2.117904 2.64 -1.8888164 0.6621802\n",
      "0.0 1.0 0.0045292606 0.06714714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb8d44feb00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "    \n",
    "    return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "for x in [inputs.numpy(), masks.numpy()]:\n",
    "    print(x.min(), x.max(), x.mean(), x.std())\n",
    "\n",
    "plt.imshow(reverse_transform(inputs[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " AvgPool2d(kernel_size=7, stride=1, padding=0),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "base_model = models.resnet18(pretrained=False)\n",
    "    \n",
    "list(base_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "        AvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 107.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "summary(base_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())                \n",
    "        \n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 256, x.H/4, x.W/4)        \n",
    "        self.layer1_1x1 = convrelu(256, 256, 1, 0)       \n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 512, x.H/8, x.W/8)        \n",
    "        self.layer2_1x1 = convrelu(512, 512, 1, 0)  \n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 1024, x.H/16, x.W/16)        \n",
    "        self.layer3_1x1 = convrelu(1024, 512, 1, 0)  \n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 2048, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(2048, 1024, 1, 0)  \n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv_up3 = convrelu(512 + 1024, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(512 + 512, 512, 3, 1)\n",
    "        self.conv_up1 = convrelu(256 + 512, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        \n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        \n",
    "        layer0 = self.layer0(input)            \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    " \n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        \n",
    "        out = self.conv_last(x)        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]           4,096\n",
      "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
      "             ReLU-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-16          [-1, 256, 56, 56]             512\n",
      "           Conv2d-17          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-18          [-1, 256, 56, 56]             512\n",
      "             ReLU-19          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-20          [-1, 256, 56, 56]               0\n",
      "           Conv2d-21           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-22           [-1, 64, 56, 56]             128\n",
      "             ReLU-23           [-1, 64, 56, 56]               0\n",
      "           Conv2d-24           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-25           [-1, 64, 56, 56]             128\n",
      "             ReLU-26           [-1, 64, 56, 56]               0\n",
      "           Conv2d-27          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-28          [-1, 256, 56, 56]             512\n",
      "             ReLU-29          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-30          [-1, 256, 56, 56]               0\n",
      "           Conv2d-31           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-32           [-1, 64, 56, 56]             128\n",
      "             ReLU-33           [-1, 64, 56, 56]               0\n",
      "           Conv2d-34           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-35           [-1, 64, 56, 56]             128\n",
      "             ReLU-36           [-1, 64, 56, 56]               0\n",
      "           Conv2d-37          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-38          [-1, 256, 56, 56]             512\n",
      "             ReLU-39          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-40          [-1, 256, 56, 56]               0\n",
      "           Conv2d-41          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-42          [-1, 128, 56, 56]             256\n",
      "             ReLU-43          [-1, 128, 56, 56]               0\n",
      "           Conv2d-44          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-45          [-1, 128, 28, 28]             256\n",
      "             ReLU-46          [-1, 128, 28, 28]               0\n",
      "           Conv2d-47          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-48          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-49          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-51          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-52          [-1, 512, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-57          [-1, 128, 28, 28]             256\n",
      "             ReLU-58          [-1, 128, 28, 28]               0\n",
      "           Conv2d-59          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-61          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-62          [-1, 512, 28, 28]               0\n",
      "           Conv2d-63          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-64          [-1, 128, 28, 28]             256\n",
      "             ReLU-65          [-1, 128, 28, 28]               0\n",
      "           Conv2d-66          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-67          [-1, 128, 28, 28]             256\n",
      "             ReLU-68          [-1, 128, 28, 28]               0\n",
      "           Conv2d-69          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-71          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-72          [-1, 512, 28, 28]               0\n",
      "           Conv2d-73          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-74          [-1, 128, 28, 28]             256\n",
      "             ReLU-75          [-1, 128, 28, 28]               0\n",
      "           Conv2d-76          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-77          [-1, 128, 28, 28]             256\n",
      "             ReLU-78          [-1, 128, 28, 28]               0\n",
      "           Conv2d-79          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-80          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-81          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-82          [-1, 512, 28, 28]               0\n",
      "           Conv2d-83          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-84          [-1, 256, 28, 28]             512\n",
      "             ReLU-85          [-1, 256, 28, 28]               0\n",
      "           Conv2d-86          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "           Conv2d-89         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-90         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-91         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-92         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-93         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-94         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-95          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-96          [-1, 256, 14, 14]             512\n",
      "             ReLU-97          [-1, 256, 14, 14]               0\n",
      "           Conv2d-98          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-99          [-1, 256, 14, 14]             512\n",
      "            ReLU-100          [-1, 256, 14, 14]               0\n",
      "          Conv2d-101         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-102         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-103         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-104         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-105          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-106          [-1, 256, 14, 14]             512\n",
      "            ReLU-107          [-1, 256, 14, 14]               0\n",
      "          Conv2d-108          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-109          [-1, 256, 14, 14]             512\n",
      "            ReLU-110          [-1, 256, 14, 14]               0\n",
      "          Conv2d-111         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-112         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-113         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-114         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-115          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-116          [-1, 256, 14, 14]             512\n",
      "            ReLU-117          [-1, 256, 14, 14]               0\n",
      "          Conv2d-118          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-119          [-1, 256, 14, 14]             512\n",
      "            ReLU-120          [-1, 256, 14, 14]               0\n",
      "          Conv2d-121         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-122         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-123         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-124         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-125          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-126          [-1, 256, 14, 14]             512\n",
      "            ReLU-127          [-1, 256, 14, 14]               0\n",
      "          Conv2d-128          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-129          [-1, 256, 14, 14]             512\n",
      "            ReLU-130          [-1, 256, 14, 14]               0\n",
      "          Conv2d-131         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-132         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-133         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-134         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-135          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-136          [-1, 256, 14, 14]             512\n",
      "            ReLU-137          [-1, 256, 14, 14]               0\n",
      "          Conv2d-138          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-139          [-1, 256, 14, 14]             512\n",
      "            ReLU-140          [-1, 256, 14, 14]               0\n",
      "          Conv2d-141         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-142         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-143         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-144         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-145          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-146          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-147          [-1, 512, 14, 14]               0\n",
      "          Conv2d-148            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-149            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-150            [-1, 512, 7, 7]               0\n",
      "          Conv2d-151           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-152           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-153           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-154           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-155           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-156           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-157            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-158            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-159            [-1, 512, 7, 7]               0\n",
      "          Conv2d-160            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-161            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-162            [-1, 512, 7, 7]               0\n",
      "          Conv2d-163           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-165           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-166           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-167            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-168            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-169            [-1, 512, 7, 7]               0\n",
      "          Conv2d-170            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-171            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-172            [-1, 512, 7, 7]               0\n",
      "          Conv2d-173           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-174           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-175           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-176           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-177           [-1, 1024, 7, 7]       2,098,176\n",
      "            ReLU-178           [-1, 1024, 7, 7]               0\n",
      "        Upsample-179         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-180          [-1, 512, 14, 14]         524,800\n",
      "            ReLU-181          [-1, 512, 14, 14]               0\n",
      "          Conv2d-182          [-1, 512, 14, 14]       7,078,400\n",
      "            ReLU-183          [-1, 512, 14, 14]               0\n",
      "        Upsample-184          [-1, 512, 28, 28]               0\n",
      "          Conv2d-185          [-1, 512, 28, 28]         262,656\n",
      "            ReLU-186          [-1, 512, 28, 28]               0\n",
      "          Conv2d-187          [-1, 512, 28, 28]       4,719,104\n",
      "            ReLU-188          [-1, 512, 28, 28]               0\n",
      "        Upsample-189          [-1, 512, 56, 56]               0\n",
      "          Conv2d-190          [-1, 256, 56, 56]          65,792\n",
      "            ReLU-191          [-1, 256, 56, 56]               0\n",
      "          Conv2d-192          [-1, 256, 56, 56]       1,769,728\n",
      "            ReLU-193          [-1, 256, 56, 56]               0\n",
      "        Upsample-194        [-1, 256, 112, 112]               0\n",
      "          Conv2d-195         [-1, 64, 112, 112]           4,160\n",
      "            ReLU-196         [-1, 64, 112, 112]               0\n",
      "          Conv2d-197        [-1, 128, 112, 112]         368,768\n",
      "            ReLU-198        [-1, 128, 112, 112]               0\n",
      "        Upsample-199        [-1, 128, 224, 224]               0\n",
      "          Conv2d-200         [-1, 64, 224, 224]         110,656\n",
      "            ReLU-201         [-1, 64, 224, 224]               0\n",
      "          Conv2d-202          [-1, 6, 224, 224]             390\n",
      "================================================================\n",
      "Total params: 40,549,382\n",
      "Trainable params: 40,549,382\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNet(6)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        \n",
    "    pred = F.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "    \n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "            \n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 0/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.070256, dice: 0.856320, loss: 0.463288\n",
      "val: bce: 0.014897, dice: 0.515814, loss: 0.265356\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 1/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.011369, dice: 0.309445, loss: 0.160407\n",
      "val: bce: 0.003790, dice: 0.113682, loss: 0.058736\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 2/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003480, dice: 0.089928, loss: 0.046704\n",
      "val: bce: 0.002525, dice: 0.067604, loss: 0.035064\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 3/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002640, dice: 0.059826, loss: 0.031233\n",
      "val: bce: 0.002230, dice: 0.059516, loss: 0.030873\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 4/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002151, dice: 0.048005, loss: 0.025078\n",
      "val: bce: 0.001772, dice: 0.048981, loss: 0.025377\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 5/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.001779, dice: 0.039846, loss: 0.020812\n",
      "val: bce: 0.001648, dice: 0.044195, loss: 0.022922\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 6/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.001570, dice: 0.035413, loss: 0.018492\n",
      "val: bce: 0.001770, dice: 0.044250, loss: 0.023010\n",
      "0m 50s\n",
      "Epoch 7/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.001363, dice: 0.031970, loss: 0.016667\n",
      "val: bce: 0.001791, dice: 0.042280, loss: 0.022035\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 8/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.001216, dice: 0.029510, loss: 0.015363\n",
      "val: bce: 0.001636, dice: 0.040241, loss: 0.020939\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 9/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.001102, dice: 0.026798, loss: 0.013950\n",
      "val: bce: 0.001550, dice: 0.038254, loss: 0.019902\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 10/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.001022, dice: 0.024261, loss: 0.012641\n",
      "val: bce: 0.001892, dice: 0.038144, loss: 0.020018\n",
      "0m 51s\n",
      "Epoch 11/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000966, dice: 0.023030, loss: 0.011998\n",
      "val: bce: 0.001807, dice: 0.040560, loss: 0.021183\n",
      "0m 51s\n",
      "Epoch 12/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000959, dice: 0.022332, loss: 0.011646\n",
      "val: bce: 0.001545, dice: 0.037748, loss: 0.019646\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 13/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000954, dice: 0.021886, loss: 0.011420\n",
      "val: bce: 0.001583, dice: 0.035522, loss: 0.018553\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 14/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000903, dice: 0.020732, loss: 0.010818\n",
      "val: bce: 0.001605, dice: 0.034511, loss: 0.018058\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 15/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000875, dice: 0.020229, loss: 0.010552\n",
      "val: bce: 0.001735, dice: 0.036320, loss: 0.019028\n",
      "0m 51s\n",
      "Epoch 16/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000846, dice: 0.019502, loss: 0.010174\n",
      "val: bce: 0.001603, dice: 0.035112, loss: 0.018357\n",
      "0m 51s\n",
      "Epoch 17/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000828, dice: 0.018908, loss: 0.009868\n",
      "val: bce: 0.001738, dice: 0.035582, loss: 0.018660\n",
      "0m 50s\n",
      "Epoch 18/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000786, dice: 0.018146, loss: 0.009466\n",
      "val: bce: 0.001639, dice: 0.035409, loss: 0.018524\n",
      "0m 50s\n",
      "Epoch 19/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000778, dice: 0.017965, loss: 0.009372\n",
      "val: bce: 0.001559, dice: 0.034482, loss: 0.018021\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 20/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000776, dice: 0.017846, loss: 0.009311\n",
      "val: bce: 0.001529, dice: 0.033766, loss: 0.017648\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 21/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000786, dice: 0.017658, loss: 0.009222\n",
      "val: bce: 0.001434, dice: 0.033253, loss: 0.017343\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 22/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000761, dice: 0.017041, loss: 0.008901\n",
      "val: bce: 0.001787, dice: 0.034738, loss: 0.018262\n",
      "0m 50s\n",
      "Epoch 23/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000743, dice: 0.016727, loss: 0.008735\n",
      "val: bce: 0.001595, dice: 0.032887, loss: 0.017241\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 24/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000762, dice: 0.017094, loss: 0.008928\n",
      "val: bce: 0.001476, dice: 0.031623, loss: 0.016550\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 25/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000738, dice: 0.016564, loss: 0.008651\n",
      "val: bce: 0.001653, dice: 0.031632, loss: 0.016643\n",
      "0m 51s\n",
      "Epoch 26/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000787, dice: 0.017148, loss: 0.008967\n",
      "val: bce: 0.001526, dice: 0.032351, loss: 0.016938\n",
      "0m 51s\n",
      "Epoch 27/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000730, dice: 0.016158, loss: 0.008444\n",
      "val: bce: 0.001611, dice: 0.032429, loss: 0.017020\n",
      "0m 51s\n",
      "Epoch 28/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000690, dice: 0.015567, loss: 0.008128\n",
      "val: bce: 0.001666, dice: 0.033520, loss: 0.017593\n",
      "0m 51s\n",
      "Epoch 29/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.000671, dice: 0.015082, loss: 0.007877\n",
      "val: bce: 0.001575, dice: 0.033148, loss: 0.017362\n",
      "0m 51s\n",
      "Epoch 30/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000641, dice: 0.014402, loss: 0.007521\n",
      "val: bce: 0.001460, dice: 0.031846, loss: 0.016653\n",
      "0m 50s\n",
      "Epoch 31/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000600, dice: 0.013728, loss: 0.007164\n",
      "val: bce: 0.001452, dice: 0.031908, loss: 0.016680\n",
      "0m 50s\n",
      "Epoch 32/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000592, dice: 0.013455, loss: 0.007023\n",
      "val: bce: 0.001445, dice: 0.031674, loss: 0.016559\n",
      "0m 51s\n",
      "Epoch 33/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000574, dice: 0.013168, loss: 0.006871\n",
      "val: bce: 0.001431, dice: 0.031539, loss: 0.016485\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 34/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000569, dice: 0.012981, loss: 0.006775\n",
      "val: bce: 0.001428, dice: 0.031582, loss: 0.016505\n",
      "0m 51s\n",
      "Epoch 35/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000564, dice: 0.012798, loss: 0.006681\n",
      "val: bce: 0.001429, dice: 0.031574, loss: 0.016502\n",
      "0m 51s\n",
      "Epoch 36/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000561, dice: 0.012605, loss: 0.006583\n",
      "val: bce: 0.001436, dice: 0.031709, loss: 0.016572\n",
      "0m 51s\n",
      "Epoch 37/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000556, dice: 0.012459, loss: 0.006508\n",
      "val: bce: 0.001432, dice: 0.031532, loss: 0.016482\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 38/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000554, dice: 0.012263, loss: 0.006408\n",
      "val: bce: 0.001444, dice: 0.031641, loss: 0.016543\n",
      "0m 51s\n",
      "Epoch 39/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000555, dice: 0.012101, loss: 0.006328\n",
      "val: bce: 0.001453, dice: 0.031530, loss: 0.016492\n",
      "0m 51s\n",
      "Epoch 40/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000557, dice: 0.011972, loss: 0.006265\n",
      "val: bce: 0.001473, dice: 0.031550, loss: 0.016511\n",
      "0m 51s\n",
      "Epoch 41/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000556, dice: 0.011858, loss: 0.006207\n",
      "val: bce: 0.001465, dice: 0.031489, loss: 0.016477\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 42/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000554, dice: 0.011740, loss: 0.006147\n",
      "val: bce: 0.001456, dice: 0.031327, loss: 0.016391\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 43/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000549, dice: 0.011589, loss: 0.006069\n",
      "val: bce: 0.001469, dice: 0.031460, loss: 0.016464\n",
      "0m 50s\n",
      "Epoch 44/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000551, dice: 0.011502, loss: 0.006026\n",
      "val: bce: 0.001474, dice: 0.031306, loss: 0.016390\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 45/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000550, dice: 0.011395, loss: 0.005972\n",
      "val: bce: 0.001480, dice: 0.031193, loss: 0.016336\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 46/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000548, dice: 0.011287, loss: 0.005917\n",
      "val: bce: 0.001485, dice: 0.031277, loss: 0.016381\n",
      "0m 50s\n",
      "Epoch 47/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000546, dice: 0.011192, loss: 0.005869\n",
      "val: bce: 0.001495, dice: 0.031401, loss: 0.016448\n",
      "0m 51s\n",
      "Epoch 48/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000546, dice: 0.011096, loss: 0.005821\n",
      "val: bce: 0.001474, dice: 0.031231, loss: 0.016352\n",
      "0m 50s\n",
      "Epoch 49/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000542, dice: 0.011033, loss: 0.005787\n",
      "val: bce: 0.001512, dice: 0.031240, loss: 0.016376\n",
      "0m 50s\n",
      "Epoch 50/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000540, dice: 0.010925, loss: 0.005732\n",
      "val: bce: 0.001527, dice: 0.031299, loss: 0.016413\n",
      "0m 51s\n",
      "Epoch 51/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000538, dice: 0.010794, loss: 0.005666\n",
      "val: bce: 0.001509, dice: 0.031244, loss: 0.016377\n",
      "0m 50s\n",
      "Epoch 52/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000535, dice: 0.010693, loss: 0.005614\n",
      "val: bce: 0.001516, dice: 0.031133, loss: 0.016324\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 53/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000531, dice: 0.010627, loss: 0.005579\n",
      "val: bce: 0.001517, dice: 0.031027, loss: 0.016272\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 54/59\n",
      "----------\n",
      "LR 1e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: bce: 0.000529, dice: 0.010534, loss: 0.005532\n",
      "val: bce: 0.001527, dice: 0.031000, loss: 0.016264\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 55/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000524, dice: 0.010475, loss: 0.005500\n",
      "val: bce: 0.001527, dice: 0.030887, loss: 0.016207\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 56/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000523, dice: 0.010416, loss: 0.005469\n",
      "val: bce: 0.001524, dice: 0.030817, loss: 0.016171\n",
      "saving best model\n",
      "0m 51s\n",
      "Epoch 57/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000523, dice: 0.010289, loss: 0.005406\n",
      "val: bce: 0.001558, dice: 0.030965, loss: 0.016261\n",
      "0m 51s\n",
      "Epoch 58/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000518, dice: 0.010209, loss: 0.005364\n",
      "val: bce: 0.001548, dice: 0.031034, loss: 0.016291\n",
      "0m 51s\n",
      "Epoch 59/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.000518, dice: 0.010168, loss: 0.005343\n",
      "val: bce: 0.001566, dice: 0.030785, loss: 0.016176\n",
      "0m 50s\n",
      "Best val loss: 0.016171\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 6\n",
    "\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "#for l in model.base_layers:\n",
    "#    for param in l.parameters():\n",
    "#        param.requires_grad = False\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)        \n",
    "        \n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 192, 192)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### prediction\n",
    "\n",
    "import math\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "        \n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = model(inputs)\n",
    "pred = F.sigmoid(pred)\n",
    "pred = pred.data.cpu().numpy()\n",
    "print(pred.shape)\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
