{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 192, 192, 3)\n",
      "0 255\n",
      "(3, 6, 192, 192)\n",
      "0.0 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation\n",
    "from matplotlib.image import imread\n",
    "\n",
    "# Generate some random images\n",
    "input_images, target_masks = simulation.generate_random_data(192, 192, count=3)\n",
    "# other_input_images = np.array([imread('./images/output_0_1.png'), imread('./images/output_2_2.png'), imread('./images/output_9_1.png')])\n",
    "# other_target_masks = np.array([imread('./images/output_0_1.png'), imread('./images/output_2_2.png'), imread('./images/output_9_1.png')])\n",
    "\n",
    "for x in [input_images, target_masks]:\n",
    "    print(x.shape)\n",
    "    print(x.min(), x.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "# print(np.array(input_images_rgb).shape)\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "# Left: Input image, Right: Target mask\n",
    "helper.plot_side_by_side([input_images, target_masks_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0\n",
      "0.0\n",
      "[[41. 41. 41. ...  0.  0.  0.]\n",
      " [41. 41. 41. ...  0.  0.  0.]\n",
      " [41. 41. 41. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 3.  3.  3. ...  0.  0.  0.]\n",
      " [ 3.  3.  3. ...  0.  0.  0.]\n",
      " [ 3.  2.  2. ...  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "dirs = './segmented_images/'\n",
    "files = os.listdir(dirs)\n",
    "# print(files[0])\n",
    "segmented_images = np.array([np.load(dirs + str(files[i])) for i in range(len(files))])\n",
    "print(segmented_images[0].max())\n",
    "print(segmented_images[0].min())\n",
    "print(segmented_images[0][80 : -80, 80 : -80])\n",
    "\n",
    "# dirs = '/A/'\n",
    "# files = os.listdir(dirs)\n",
    "# data = [imread(files[i]) for i in range(len(files))]\n",
    "\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms, datasets, models\n",
    "\n",
    "# class SimDataset(Dataset):\n",
    "#     def __init__(self, count, transform=None):\n",
    "#         self.input_images, self.target_masks = simulation.generate_random_data(192, 192, count=count)        \n",
    "#         self.transform = transform\n",
    "#         print(self.input_images.shape)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.input_images)\n",
    "    \n",
    "#     def __getitem__(self, idx):        \n",
    "#         image = self.input_images[idx]\n",
    "#         mask = self.target_masks[idx]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "        \n",
    "#         return [image, mask]\n",
    "\n",
    "# # use same transform for train/val for this example\n",
    "# trans = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "# ])\n",
    "\n",
    "# train_set = SimDataset(2000, transform=trans)\n",
    "# val_set = SimDataset(200, transform=trans)\n",
    "\n",
    "# image_datasets = {\n",
    "#     'train': train_set, 'val': val_set\n",
    "# }\n",
    "\n",
    "# batch_size = 25\n",
    "\n",
    "# dataloaders = {\n",
    "#     'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "#     'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "# }\n",
    "\n",
    "# dataset_sizes = {\n",
    "#     x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "# }\n",
    "\n",
    "# dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 1500, 'val': 500}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function that reshapes the input image to have 1 as the number of channels\n",
    "def makeInput(image):\n",
    "    # print(image.shape)\n",
    "    return image.reshape((image.shape[0], image.shape[1], 1))\n",
    "\n",
    "# ROIList = [2, 3, 41, 42]\n",
    "def makeSeg(image):\n",
    "    \n",
    "    image = image.reshape((image.shape[0], image.shape[1], 1))\n",
    "    foreground = np.zeros(image.shape)\n",
    "    first = np.zeros(image.shape)\n",
    "    first[image == 2] == 1\n",
    "    foreground[image == 2] == 1\n",
    "    second = np.zeros(image.shape)\n",
    "    second[image == 3] == 1\n",
    "    foreground[image == 3] == 1\n",
    "    third = np.zeros(image.shape)\n",
    "    third[image == 41] == 1\n",
    "    foreground[image == 41] == 1\n",
    "    fourth = np.zeros(image.shape)\n",
    "    fourth[image == 42] == 1\n",
    "    foreground[image == 42] == 1\n",
    "    fifth = np.zeros(image.shape)\n",
    "    fifth[foreground == 0] == 1\n",
    "    \n",
    "    return np.concatenate((first, second, third, fourth, fifth), axis=2)\n",
    "    \n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, train=True, transform=None):\n",
    "        if train:\n",
    "            dirs = './original_images/'\n",
    "            files = os.listdir(dirs)\n",
    "            # print(files[0])\n",
    "            self.input_images = np.array([makeInput(np.load(dirs + str(files[i]))) for i in range(len(files))])\n",
    "            # print(self.input_images.shape)\n",
    "            dirs = './segmented_images/'\n",
    "            files = os.listdir(dirs)\n",
    "            self.target_masks = np.array([makeSeg(np.load(dirs + str(files[i]))) for i in range(len(files))])\n",
    "        else:\n",
    "            dirs = './validation_original_images/'\n",
    "            files = os.listdir(dirs)\n",
    "            self.input_images = np.array([makeInput(np.load(dirs + str(files[i]))) for i in range(len(files))])\n",
    "            dirs = './validation_segmented_images/'\n",
    "            files = os.listdir(dirs)\n",
    "            self.target_masks = np.array([makeSeg(np.load(dirs + str(files[i]))) for i in range(len(files))])\n",
    "        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            transformation = self.transform\n",
    "            image = transformation(image)\n",
    "            mask = transformation(mask)\n",
    "        \n",
    "        return [image, mask]\n",
    "\n",
    "# use same transform for train/val for this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Resize(192), # Added this line\n",
    "    # transforms.RandomCrop(180), # Added this line\n",
    "    # transforms.RandomRotation(10), # Added this line\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "train_set = SimDataset(train=True, transform=trans)\n",
    "val_set = SimDataset(train=False, transform=trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 1, 256, 256]) torch.Size([25, 5, 256, 256])\n",
      "-2.1179039301310043 2.2489082969432315 -1.6778606831656169 0.7496853449460744\n",
      "-2.1179039301310043 0.0 -1.1916125320579487 0.9783626455077156\n"
     ]
    }
   ],
   "source": [
    "import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "    \n",
    "    return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "for x in [inputs.numpy(), masks.numpy()]:\n",
    "    print(x.min(), x.max(), x.mean(), x.std())\n",
    "\n",
    "# plt.imshow(reverse_transform(inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 1, 256, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " AvgPool2d(kernel_size=7, stride=1, padding=0),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "base_model = models.resnet18(pretrained=False)\n",
    "    \n",
    "list(base_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "        AvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 107.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "summary(base_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())                \n",
    "        \n",
    "        self.layersi = convrelu(1, 3,1,0)\n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)        \n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)       \n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)        \n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)  \n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)        \n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)  \n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)  \n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        \n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        layersi = self.layersi(input)\n",
    "        x_original = self.conv_original_size0(layersi)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        \n",
    "        layer0 = self.layer0(layersi)            \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    " \n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        \n",
    "        out = self.conv_last(x)        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajay/anaconda3/envs/ECE4250_Assignments/lib/python3.7/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 3, 256, 256]               6\n",
      "              ReLU-2          [-1, 3, 256, 256]               0\n",
      "            Conv2d-3         [-1, 64, 256, 256]           1,792\n",
      "              ReLU-4         [-1, 64, 256, 256]               0\n",
      "            Conv2d-5         [-1, 64, 256, 256]          36,928\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "            Conv2d-7         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-8         [-1, 64, 128, 128]             128\n",
      "              ReLU-9         [-1, 64, 128, 128]               0\n",
      "        MaxPool2d-10           [-1, 64, 64, 64]               0\n",
      "           Conv2d-11           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-12           [-1, 64, 64, 64]             128\n",
      "             ReLU-13           [-1, 64, 64, 64]               0\n",
      "           Conv2d-14           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 64, 64]             128\n",
      "             ReLU-16           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-17           [-1, 64, 64, 64]               0\n",
      "           Conv2d-18           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-19           [-1, 64, 64, 64]             128\n",
      "             ReLU-20           [-1, 64, 64, 64]               0\n",
      "           Conv2d-21           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 64, 64]             128\n",
      "             ReLU-23           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-24           [-1, 64, 64, 64]               0\n",
      "           Conv2d-25          [-1, 128, 32, 32]          73,728\n",
      "      BatchNorm2d-26          [-1, 128, 32, 32]             256\n",
      "             ReLU-27          [-1, 128, 32, 32]               0\n",
      "           Conv2d-28          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
      "           Conv2d-30          [-1, 128, 32, 32]           8,192\n",
      "      BatchNorm2d-31          [-1, 128, 32, 32]             256\n",
      "             ReLU-32          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-33          [-1, 128, 32, 32]               0\n",
      "           Conv2d-34          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-35          [-1, 128, 32, 32]             256\n",
      "             ReLU-36          [-1, 128, 32, 32]               0\n",
      "           Conv2d-37          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
      "             ReLU-39          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-40          [-1, 128, 32, 32]               0\n",
      "           Conv2d-41          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-42          [-1, 256, 16, 16]             512\n",
      "             ReLU-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "           Conv2d-46          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-47          [-1, 256, 16, 16]             512\n",
      "             ReLU-48          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-49          [-1, 256, 16, 16]               0\n",
      "           Conv2d-50          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-51          [-1, 256, 16, 16]             512\n",
      "             ReLU-52          [-1, 256, 16, 16]               0\n",
      "           Conv2d-53          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-54          [-1, 256, 16, 16]             512\n",
      "             ReLU-55          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-56          [-1, 256, 16, 16]               0\n",
      "           Conv2d-57            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-58            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-62            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-63            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-64            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-65            [-1, 512, 8, 8]               0\n",
      "           Conv2d-66            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-67            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-68            [-1, 512, 8, 8]               0\n",
      "           Conv2d-69            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-70            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-71            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-72            [-1, 512, 8, 8]               0\n",
      "           Conv2d-73            [-1, 512, 8, 8]         262,656\n",
      "             ReLU-74            [-1, 512, 8, 8]               0\n",
      "         Upsample-75          [-1, 512, 16, 16]               0\n",
      "           Conv2d-76          [-1, 256, 16, 16]          65,792\n",
      "             ReLU-77          [-1, 256, 16, 16]               0\n",
      "           Conv2d-78          [-1, 512, 16, 16]       3,539,456\n",
      "             ReLU-79          [-1, 512, 16, 16]               0\n",
      "         Upsample-80          [-1, 512, 32, 32]               0\n",
      "           Conv2d-81          [-1, 128, 32, 32]          16,512\n",
      "             ReLU-82          [-1, 128, 32, 32]               0\n",
      "           Conv2d-83          [-1, 256, 32, 32]       1,474,816\n",
      "             ReLU-84          [-1, 256, 32, 32]               0\n",
      "         Upsample-85          [-1, 256, 64, 64]               0\n",
      "           Conv2d-86           [-1, 64, 64, 64]           4,160\n",
      "             ReLU-87           [-1, 64, 64, 64]               0\n",
      "           Conv2d-88          [-1, 256, 64, 64]         737,536\n",
      "             ReLU-89          [-1, 256, 64, 64]               0\n",
      "         Upsample-90        [-1, 256, 128, 128]               0\n",
      "           Conv2d-91         [-1, 64, 128, 128]           4,160\n",
      "             ReLU-92         [-1, 64, 128, 128]               0\n",
      "           Conv2d-93        [-1, 128, 128, 128]         368,768\n",
      "             ReLU-94        [-1, 128, 128, 128]               0\n",
      "         Upsample-95        [-1, 128, 256, 256]               0\n",
      "           Conv2d-96         [-1, 64, 256, 256]         110,656\n",
      "             ReLU-97         [-1, 64, 256, 256]               0\n",
      "           Conv2d-98          [-1, 5, 256, 256]             325\n",
      "================================================================\n",
      "Total params: 17,800,075\n",
      "Trainable params: 17,800,075\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 466.00\n",
      "Params size (MB): 67.90\n",
      "Estimated Total Size (MB): 534.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check keras-like model summary using torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNet(5)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from loss import dice_loss\n",
    "\n",
    "# Function that calculates the Jaccard overlap between two images for a given ROI\n",
    "def JaccardOverlap(first, second, region):\n",
    "    firstOther = np.zeros(first.shape)\n",
    "    secondOther = np.zeros(second.shape)\n",
    "    \n",
    "    firstOther[first == region] = 1\n",
    "    secondOther[second == region] = 1\n",
    "    \n",
    "    firstOther = firstOther.astype(bool)\n",
    "    secondOther = secondOther.astype(bool)\n",
    "    \n",
    "    \n",
    "    firstCount = np.sum(firstOther)\n",
    "    secondCount = np.sum(secondOther)\n",
    "    \n",
    "    \n",
    "    intersectionCount = np.sum(np.bitwise_and(firstOther.reshape(first.size), secondOther.reshape(second.size)))\n",
    "    \n",
    "    return intersectionCount / (firstCount + secondCount - intersectionCount)\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred.float(), target.float())\n",
    "        \n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "    \n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "    \n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float) # Changed this line\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.float().to(device)\n",
    "                labels = labels.float().to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "            \n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 0/14\n",
      "----------\n",
      "LR 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d84e8934d976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-c4e88edd498f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ECE4250_Assignments/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-0c81a5bfa1cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mlayer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mlayer3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mlayer4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ECE4250_Assignments/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ECE4250_Assignments/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ECE4250_Assignments/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ECE4250_Assignments/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ECE4250_Assignments/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ECE4250_Assignments/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 5\n",
    "\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "# Comment out to finetune further\n",
    "for l in model.base_layers:\n",
    "    for param in l.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)        \n",
    "        \n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### prediction\n",
    "\n",
    "import math\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "        \n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "pred = model(inputs)\n",
    "pred = torch.sigmoid(pred)\n",
    "pred = pred.data.cpu().numpy()\n",
    "print(pred.shape)\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])\n",
    "print('Jaccard Overlap: ', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
